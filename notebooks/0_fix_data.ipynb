{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_link,product_link\n",
    "# <div id=\"imgTagWrapperId\" class=\"imgTagWrapper\" role=\"button\" tabindex=\"0\" style=\"height: 408px;\" bis_skin_checked=\"1\">\n",
    "#                         <img alt=\"Wayona [Apple MFi Certified Charger Lightning to USB Charging Cable Cord Compatible iPhone 14/13/12/11 Pro/11/XS MAX/XR/8/7/6s Plus,iPad Pro/Air/Mini\" src=\"https://m.media-amazon.com/images/I/71ojkmsYe8L._SX522_.jpg\" data-old-hires=\"https://m.media-amazon.com/images/I/71ojkmsYe8L._SL1100_.jpg\" onload=\"markFeatureRenderForImageBlock(); this.onload='';setCSMReq('af');if(typeof addlongPoleTag === 'function'){ addlongPoleTag('af','desktop-image-atf-marker');};setCSMReq('cf')\" data-a-image-name=\"landingImage\" class=\"a-dynamic-image a-stretch-vertical\" id=\"landingImage\" data-a-dynamic-image=\"{&quot;https://m.media-amazon.com/images/I/71ojkmsYe8L._SX425_.jpg&quot;:[425,425],&quot;https://m.media-amazon.com/images/I/71ojkmsYe8L._SX522_.jpg&quot;:[522,522],&quot;https://m.media-amazon.com/images/I/71ojkmsYe8L._SY450_.jpg&quot;:[450,450],&quot;https://m.media-amazon.com/images/I/71ojkmsYe8L._SX569_.jpg&quot;:[569,569],&quot;https://m.media-amazon.com/images/I/71ojkmsYe8L._SY355_.jpg&quot;:[355,355],&quot;https://m.media-amazon.com/images/I/71ojkmsYe8L._SX466_.jpg&quot;:[466,466],&quot;https://m.media-amazon.com/images/I/71ojkmsYe8L._SX679_.jpg&quot;:[679,679]}\" style=\"max-width: 408px; max-height: 408px;\"> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d04da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from file: ../data/raw/process_amazon.csv\n",
      "Starting to check existing image links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking links: 100%|██████████| 1465/1465 [08:45<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 32 broken image links. Starting to re-scrape...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-scraping broken links: 100%|██████████| 32/32 [01:05<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process completed!\n",
      "Total number of image links successfully updated: 0/32\n",
      "Successfully saved the updated file at: ../data/raw/process_amazon.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE_PATH = '../data/raw/process_amazon.csv'\n",
    "OUTPUT_FILE_PATH = '../data/raw/process_amazon.csv'  # Overwrite the old file\n",
    "\n",
    "# Simulate browser headers to avoid being blocked\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "def check_image_link(img_url: str) -> bool:\n",
    "    if not isinstance(img_url, str) or not img_url.startswith('http'):\n",
    "        return False\n",
    "    try:\n",
    "        # Use HEAD method to get only headers, not download the image\n",
    "        response = requests.head(img_url, headers=HEADERS, timeout=10, allow_redirects=True)\n",
    "        # If status code is 200 (OK), the link is valid\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "    except requests.exceptions.RequestException:\n",
    "        # Any network error is considered as a broken link\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def get_correct_image_url(product_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Truy cập URL của sản phẩm và trích xuất link ảnh chính xác từ thẻ div#imgTagWrapperId.\n",
    "    \"\"\"\n",
    "    if not isinstance(product_url, str) or not product_url.startswith('http'):\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        response = requests.get(product_url, headers=HEADERS, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            img_wrapper = soup.find('div', id='imgTagWrapperId')\n",
    "            if img_wrapper:\n",
    "                image_tag = img_wrapper.find('img')\n",
    "                if image_tag and 'src' in image_tag.attrs:\n",
    "                    return image_tag['src']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  Error when scraping data from URL: {product_url} - {e}\")\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính để đọc file, chỉ cào lại các link ảnh bị lỗi và lưu file.\n",
    "    \"\"\"\n",
    "    print(f\"Reading data from file: {INPUT_FILE_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_FILE_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found '{INPUT_FILE_PATH}'.\")\n",
    "        return\n",
    "\n",
    "    # Find indices of rows with broken image links\n",
    "    print(\"Starting to check existing image links...\")\n",
    "    broken_link_indices = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Checking links\"):\n",
    "        if not check_image_link(row['img_link']):\n",
    "            broken_link_indices.append(index)\n",
    "        # Add a small delay to avoid sending too many HEAD requests at once\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    print(f\"\\nFound {len(broken_link_indices)} broken image links. Starting to re-scrape...\")\n",
    "\n",
    "    updated_count = 0\n",
    "    if not broken_link_indices:\n",
    "        print(\"All image links are working fine. No update needed.\")\n",
    "    else:\n",
    "        # Only iterate and re-scrape rows with broken links\n",
    "        for index in tqdm(broken_link_indices, desc=\"Re-scraping broken links\"):\n",
    "            product_link = df.at[index, 'product_link']\n",
    "            \n",
    "            # Get new image link\n",
    "            new_url = get_correct_image_url(product_link)\n",
    "            \n",
    "            if new_url:\n",
    "                # Update directly in DataFrame\n",
    "                df.at[index, 'img_link'] = new_url\n",
    "                updated_count += 1\n",
    "            \n",
    "            # Pause to avoid being blocked\n",
    "            time.sleep(random.uniform(0.8, 2.0))\n",
    "\n",
    "    print(\"\\nProcess completed!\")\n",
    "    print(f\"Total number of image links successfully updated: {updated_count}/{len(broken_link_indices)}\")\n",
    "\n",
    "    # Save the file\n",
    "    try:\n",
    "        df.to_csv(OUTPUT_FILE_PATH, index=False)\n",
    "        print(f\"Successfully saved the updated file at: {OUTPUT_FILE_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error when saving file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
