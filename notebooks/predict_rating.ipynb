{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b7ff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AMAZON PRODUCT RATING PREDICTION\n",
      "Strategy: Baseline → Tree-based → Advanced\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "1. DATA LOADING\n",
      "======================================================================\n",
      "✓ Loaded: 1351 rows, 25 columns\n",
      "\n",
      "Target: rating\n",
      "  Range: 2.0 - 5.0\n",
      "  Mean:  4.09\n",
      "  Std:   0.30\n",
      "\n",
      "======================================================================\n",
      "2. FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "✓ Engineered 11 features:\n",
      "  - rating_count\n",
      "  - discounted_price\n",
      "  - actual_price\n",
      "  - discount_percentage\n",
      "  - price_ratio\n",
      "  - discount_amount\n",
      "  - log_rating_count\n",
      "  - is_high_discount\n",
      "  - category_encoded\n",
      "  - price_category_encoded\n",
      "  - product_name_length\n",
      "\n",
      "✓ Feature matrix: (1351, 11)\n",
      "✓ Target vector: (1351,)\n",
      "✓ Missing values: 0\n",
      "\n",
      "======================================================================\n",
      "3. TRAIN-TEST SPLIT\n",
      "======================================================================\n",
      "✓ Train: 1080 samples\n",
      "✓ Test:  271 samples\n",
      "✓ Train mean: 4.092\n",
      "✓ Test mean:  4.091\n",
      "✓ Features scaled\n",
      "\n",
      "======================================================================\n",
      "PHASE 1: BASELINE MODELS\n",
      "======================================================================\n",
      "\n",
      "[1.1] Mean Predictor...\n",
      "  MAE:  0.2209\n",
      "  RMSE: 0.3023\n",
      "  R²:   -0.0000\n",
      "\n",
      "[1.2] Linear Regression...\n",
      "  MAE:    0.2093\n",
      "  RMSE:   0.2791\n",
      "  R²:     0.1479\n",
      "  CV MAE: 0.2110\n",
      "\n",
      "[1.3] Ridge Regression...\n",
      "  MAE:    0.2091\n",
      "  RMSE:   0.2790\n",
      "  R²:     0.1485\n",
      "  CV MAE: 0.2109\n",
      "\n",
      "======================================================================\n",
      "PHASE 2: TREE-BASED MODELS\n",
      "======================================================================\n",
      "\n",
      "[2.1] Decision Tree...\n",
      "  MAE:    0.2329\n",
      "  RMSE:   0.3256\n",
      "  R²:     -0.1601\n",
      "  CV MAE: 0.2296\n",
      "\n",
      "[2.2] Random Forest...\n",
      "  MAE:    0.1926\n",
      "  RMSE:   0.2693\n",
      "  R²:     0.2067\n",
      "  CV MAE: 0.2004\n",
      "\n",
      "[2.3] Gradient Boosting...\n",
      "  MAE:    0.2076\n",
      "  RMSE:   0.2856\n",
      "  R²:     0.1073\n",
      "  CV MAE: 0.2058\n",
      "\n",
      "======================================================================\n",
      "PHASE 3: ADVANCED MODELS\n",
      "======================================================================\n",
      "\n",
      "[3.1] XGBoost...\n",
      "  MAE:    0.1981\n",
      "  RMSE:   0.2751\n",
      "  R²:     0.1722\n",
      "  CV MAE: 0.2078\n",
      "\n",
      "======================================================================\n",
      "PHASE 4: MODEL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "     Phase             Model      MAE     RMSE        R²   CV_MAE\n",
      "  Baseline    Mean Predictor 0.220939 0.302312 -0.000020 0.220939\n",
      "  Baseline Linear Regression 0.209292 0.279067  0.147856 0.211027\n",
      "  Baseline             Ridge 0.209140 0.278967  0.148465 0.210853\n",
      "Tree-based     Decision Tree 0.232921 0.325606 -0.160064 0.229639\n",
      "Tree-based     Random Forest 0.192554 0.269262  0.206681 0.200360\n",
      "Tree-based Gradient Boosting 0.207585 0.285627  0.107323 0.205847\n",
      "  Advanced           XGBoost 0.198074 0.275057  0.172166 0.207785\n",
      "\n",
      "======================================================================\n",
      "BEST MODEL: Random Forest\n",
      "  MAE:  0.1926\n",
      "  R²:   0.2067\n",
      "  Improvement: 12.8% vs baseline\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "5. FEATURE IMPORTANCE (Best Model)\n",
      "======================================================================\n",
      "\n",
      "Top 10 Features:\n",
      "               Feature  Importance\n",
      "      log_rating_count    0.157824\n",
      "          rating_count    0.153233\n",
      "   product_name_length    0.148126\n",
      "       discount_amount    0.140989\n",
      "      discounted_price    0.110847\n",
      "           price_ratio    0.098605\n",
      "          actual_price    0.070578\n",
      "      category_encoded    0.063242\n",
      "   discount_percentage    0.045254\n",
      "price_category_encoded    0.010025\n",
      "\n",
      "======================================================================\n",
      "6. SAVING RESULTS\n",
      "======================================================================\n",
      "✓ Model saved: ../models/rating_prediction_model.pkl\n",
      "✓ Results saved: ../results/model_comparison.csv\n",
      "\n",
      "======================================================================\n",
      "MODEL TRAINING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# AMAZON PRODUCT RATING PREDICTION MODEL\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AMAZON PRODUCT RATING PREDICTION\")\n",
    "print(\"Strategy: Baseline → Tree-based → Advanced\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. DATA LOADING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df = pd.read_csv('../data/processed/amazon.csv')\n",
    "\n",
    "print(f\"✓ Loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nTarget: rating\")\n",
    "print(f\"  Range: {df['rating'].min():.1f} - {df['rating'].max():.1f}\")\n",
    "print(f\"  Mean:  {df['rating'].mean():.2f}\")\n",
    "print(f\"  Std:   {df['rating'].std():.2f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. FEATURE ENGINEERING (NO REVIEW DATA)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Parse numeric features\n",
    "numeric_cols = ['discounted_price', 'actual_price', 'discount_percentage', 'rating_count']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].astype(str).str.replace('₹', '').str.replace(',', '').str.replace('%', '')\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Handle missing\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Derived features\n",
    "df['price_ratio'] = df['discounted_price'] / df['actual_price']\n",
    "df['discount_amount'] = df['actual_price'] - df['discounted_price']\n",
    "df['log_rating_count'] = np.log1p(df['rating_count'])\n",
    "df['is_high_discount'] = (df['discount_percentage'] > 0.5).astype(int)\n",
    "\n",
    "# Price category\n",
    "df['price_category'] = pd.cut(\n",
    "    df['actual_price'], \n",
    "    bins=[0, 500, 2000, 10000, float('inf')],\n",
    "    labels=['budget', 'mid', 'premium', 'luxury']\n",
    ")\n",
    "\n",
    "# Category encoding\n",
    "if 'category' in df.columns:\n",
    "    df['category_main'] = df['category'].str.split('|').str[0]\n",
    "    le_category = LabelEncoder()\n",
    "    df['category_encoded'] = le_category.fit_transform(df['category_main'].fillna('Unknown'))\n",
    "else:\n",
    "    df['category_encoded'] = 0\n",
    "\n",
    "# Product name length\n",
    "if 'product_name' in df.columns:\n",
    "    df['product_name_length'] = df['product_name'].str.len()\n",
    "else:\n",
    "    df['product_name_length'] = 0\n",
    "\n",
    "# Price category encoding\n",
    "le_price = LabelEncoder()\n",
    "df['price_category_encoded'] = le_price.fit_transform(df['price_category'].astype(str))\n",
    "\n",
    "# Final feature list\n",
    "feature_cols = [\n",
    "    'rating_count',\n",
    "    'discounted_price',\n",
    "    'actual_price', \n",
    "    'discount_percentage',\n",
    "    'price_ratio',\n",
    "    'discount_amount',\n",
    "    'log_rating_count',\n",
    "    'is_high_discount',\n",
    "    'category_encoded',\n",
    "    'price_category_encoded',\n",
    "    'product_name_length'\n",
    "]\n",
    "\n",
    "print(f\"\\n✓ Engineered {len(feature_cols)} features:\")\n",
    "for feat in feature_cols:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[feature_cols].copy()\n",
    "y = df['rating'].copy()\n",
    "\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"\\n✓ Feature matrix: {X.shape}\")\n",
    "print(f\"✓ Target vector: {y.shape}\")\n",
    "print(f\"✓ Missing values: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. TRAIN-TEST SPLIT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=pd.cut(y, bins=5)\n",
    ")\n",
    "\n",
    "print(f\"✓ Train: {X_train.shape[0]} samples\")\n",
    "print(f\"✓ Test:  {X_test.shape[0]} samples\")\n",
    "print(f\"✓ Train mean: {y_train.mean():.3f}\")\n",
    "print(f\"✓ Test mean:  {y_test.mean():.3f}\")\n",
    "\n",
    "# Scaling for linear models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"✓ Features scaled\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 1: BASELINE MODELS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 1: BASELINE MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1.1 Mean Predictor\n",
    "print(\"\\n[1.1] Mean Predictor...\")\n",
    "baseline_pred = np.full(len(y_test), y_train.mean())\n",
    "mae = mean_absolute_error(y_test, baseline_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, baseline_pred))\n",
    "r2 = r2_score(y_test, baseline_pred)\n",
    "\n",
    "results.append({\n",
    "    'Phase': 'Baseline',\n",
    "    'Model': 'Mean Predictor',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'CV_MAE': mae\n",
    "})\n",
    "\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  R²:   {r2:.4f}\")\n",
    "\n",
    "# 1.2 Linear Regression\n",
    "print(\"\\n[1.2] Linear Regression...\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "cv_scores = cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae = -cv_scores.mean()\n",
    "\n",
    "results.append({\n",
    "    'Phase': 'Baseline',\n",
    "    'Model': 'Linear Regression',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'CV_MAE': cv_mae\n",
    "})\n",
    "\n",
    "print(f\"  MAE:    {mae:.4f}\")\n",
    "print(f\"  RMSE:   {rmse:.4f}\")\n",
    "print(f\"  R²:     {r2:.4f}\")\n",
    "print(f\"  CV MAE: {cv_mae:.4f}\")\n",
    "\n",
    "# 1.3 Ridge Regression\n",
    "print(\"\\n[1.3] Ridge Regression...\")\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "y_pred = ridge.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "cv_scores = cross_val_score(ridge, X_train_scaled, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae = -cv_scores.mean()\n",
    "\n",
    "results.append({\n",
    "    'Phase': 'Baseline',\n",
    "    'Model': 'Ridge',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'CV_MAE': cv_mae\n",
    "})\n",
    "\n",
    "print(f\"  MAE:    {mae:.4f}\")\n",
    "print(f\"  RMSE:   {rmse:.4f}\")\n",
    "print(f\"  R²:     {r2:.4f}\")\n",
    "print(f\"  CV MAE: {cv_mae:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 2: TREE-BASED MODELS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 2: TREE-BASED MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 2.1 Decision Tree\n",
    "print(\"\\n[2.1] Decision Tree...\")\n",
    "dt = DecisionTreeRegressor(max_depth=10, min_samples_split=20, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "cv_scores = cross_val_score(dt, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae = -cv_scores.mean()\n",
    "\n",
    "results.append({\n",
    "    'Phase': 'Tree-based',\n",
    "    'Model': 'Decision Tree',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'CV_MAE': cv_mae\n",
    "})\n",
    "\n",
    "print(f\"  MAE:    {mae:.4f}\")\n",
    "print(f\"  RMSE:   {rmse:.4f}\")\n",
    "print(f\"  R²:     {r2:.4f}\")\n",
    "print(f\"  CV MAE: {cv_mae:.4f}\")\n",
    "\n",
    "# 2.2 Random Forest\n",
    "print(\"\\n[2.2] Random Forest...\")\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae = -cv_scores.mean()\n",
    "\n",
    "results.append({\n",
    "    'Phase': 'Tree-based',\n",
    "    'Model': 'Random Forest',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'CV_MAE': cv_mae\n",
    "})\n",
    "\n",
    "print(f\"  MAE:    {mae:.4f}\")\n",
    "print(f\"  RMSE:   {rmse:.4f}\")\n",
    "print(f\"  R²:     {r2:.4f}\")\n",
    "print(f\"  CV MAE: {cv_mae:.4f}\")\n",
    "\n",
    "# 2.3 Gradient Boosting\n",
    "print(\"\\n[2.3] Gradient Boosting...\")\n",
    "gb = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "cv_scores = cross_val_score(gb, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae = -cv_scores.mean()\n",
    "\n",
    "results.append({\n",
    "    'Phase': 'Tree-based',\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'CV_MAE': cv_mae\n",
    "})\n",
    "\n",
    "print(f\"  MAE:    {mae:.4f}\")\n",
    "print(f\"  RMSE:   {rmse:.4f}\")\n",
    "print(f\"  R²:     {r2:.4f}\")\n",
    "print(f\"  CV MAE: {cv_mae:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 3: ADVANCED MODELS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 3: ADVANCED MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 3.1 XGBoost\n",
    "print(\"\\n[3.1] XGBoost...\")\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae = -cv_scores.mean()\n",
    "\n",
    "results.append({\n",
    "    'Phase': 'Advanced',\n",
    "    'Model': 'XGBoost',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R²': r2,\n",
    "    'CV_MAE': cv_mae\n",
    "})\n",
    "\n",
    "print(f\"  MAE:    {mae:.4f}\")\n",
    "print(f\"  RMSE:   {rmse:.4f}\")\n",
    "print(f\"  R²:     {r2:.4f}\")\n",
    "print(f\"  CV MAE: {cv_mae:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 4: MODEL COMPARISON & SELECTION\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 4: MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_idx = results_df['MAE'].idxmin()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "best_mae = results_df.loc[best_idx, 'MAE']\n",
    "best_r2 = results_df.loc[best_idx, 'R²']\n",
    "\n",
    "baseline_mae = results_df.loc[0, 'MAE']\n",
    "improvement = (baseline_mae - best_mae) / baseline_mae * 100\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(f\"  MAE:  {best_mae:.4f}\")\n",
    "print(f\"  R²:   {best_r2:.4f}\")\n",
    "print(f\"  Improvement: {improvement:.1f}% vs baseline\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. FEATURE IMPORTANCE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. FEATURE IMPORTANCE (Best Model)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get best model object\n",
    "model_map = {\n",
    "    'Mean Predictor': None,\n",
    "    'Linear Regression': lr,\n",
    "    'Ridge': ridge,\n",
    "    'Decision Tree': dt,\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gb,\n",
    "    'XGBoost': xgb_model\n",
    "}\n",
    "\n",
    "best_model = model_map[best_model_name]\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# 6. SAVE RESULTS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "# Save best model\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'features': feature_cols,\n",
    "    'label_encoders': {\n",
    "        'category': le_category,\n",
    "        'price': le_price\n",
    "    },\n",
    "    'metrics': results_df.loc[best_idx].to_dict()\n",
    "}\n",
    "\n",
    "with open('../models/rating_prediction_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "\n",
    "print(f\"✓ Model saved: ../models/rating_prediction_model.pkl\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../results/model_comparison.csv', index=False)\n",
    "print(f\"✓ Results saved: ../results/model_comparison.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
